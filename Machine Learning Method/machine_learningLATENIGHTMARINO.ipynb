{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1I1jsjfnv-FS"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from langdetect import detect # Library for language detection\n",
        "from spellchecker import SpellChecker\n",
        "import string\n",
        "import spacy\n",
        "from sklearn_crfsuite import CRF\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lLw_E19Jv-FV"
      },
      "outputs": [],
      "source": [
        "os.chdir('C:\\\\GitHub Repositories\\\\NLP-Detection-of-Negation-and-Uncertainty-Project-24\\\\Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dt3UhmgYv-FV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "254\n"
          ]
        }
      ],
      "source": [
        "# Loading the json file\n",
        "loading = open(\"negacio_train_v2024.json\")\n",
        "training_data = json.load(loading)\n",
        "print(len(training_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tEwRhU24xx_c",
        "outputId": "feda5902-9b46-4d44-a1a8-22b57c737369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
            "     --------------------------------------- 0.0/12.9 MB 393.8 kB/s eta 0:00:33\n",
            "     ---------------------------------------- 0.2/12.9 MB 1.1 MB/s eta 0:00:12\n",
            "     - -------------------------------------- 0.4/12.9 MB 2.0 MB/s eta 0:00:07\n",
            "     - -------------------------------------- 0.6/12.9 MB 2.5 MB/s eta 0:00:05\n",
            "     -- ------------------------------------- 0.7/12.9 MB 2.5 MB/s eta 0:00:05\n",
            "     -- ------------------------------------- 0.9/12.9 MB 3.0 MB/s eta 0:00:05\n",
            "     --- ------------------------------------ 1.1/12.9 MB 3.1 MB/s eta 0:00:04\n",
            "     ---- ----------------------------------- 1.4/12.9 MB 3.4 MB/s eta 0:00:04\n",
            "     ----- ---------------------------------- 1.6/12.9 MB 3.6 MB/s eta 0:00:04\n",
            "     ----- ---------------------------------- 1.7/12.9 MB 3.6 MB/s eta 0:00:04\n",
            "     ------ --------------------------------- 2.0/12.9 MB 3.6 MB/s eta 0:00:04\n",
            "     ------ --------------------------------- 2.2/12.9 MB 3.7 MB/s eta 0:00:03\n",
            "     ------- -------------------------------- 2.4/12.9 MB 3.8 MB/s eta 0:00:03\n",
            "     -------- ------------------------------- 2.7/12.9 MB 3.9 MB/s eta 0:00:03\n",
            "     -------- ------------------------------- 2.9/12.9 MB 3.9 MB/s eta 0:00:03\n",
            "     --------- ------------------------------ 3.0/12.9 MB 3.8 MB/s eta 0:00:03\n",
            "     ---------- ----------------------------- 3.3/12.9 MB 4.0 MB/s eta 0:00:03\n",
            "     ----------- ---------------------------- 3.6/12.9 MB 4.0 MB/s eta 0:00:03\n",
            "     ------------ --------------------------- 3.9/12.9 MB 4.1 MB/s eta 0:00:03\n",
            "     ------------ --------------------------- 4.1/12.9 MB 4.2 MB/s eta 0:00:03\n",
            "     ------------- -------------------------- 4.3/12.9 MB 4.2 MB/s eta 0:00:03\n",
            "     -------------- ------------------------- 4.6/12.9 MB 4.3 MB/s eta 0:00:02\n",
            "     -------------- ------------------------- 4.8/12.9 MB 4.3 MB/s eta 0:00:02\n",
            "     --------------- ------------------------ 5.0/12.9 MB 4.3 MB/s eta 0:00:02\n",
            "     ---------------- ----------------------- 5.4/12.9 MB 4.5 MB/s eta 0:00:02\n",
            "     ----------------- ---------------------- 5.5/12.9 MB 4.4 MB/s eta 0:00:02\n",
            "     ----------------- ---------------------- 5.8/12.9 MB 4.5 MB/s eta 0:00:02\n",
            "     ------------------ --------------------- 5.9/12.9 MB 4.4 MB/s eta 0:00:02\n",
            "     ------------------- -------------------- 6.3/12.9 MB 4.5 MB/s eta 0:00:02\n",
            "     ------------------- -------------------- 6.4/12.9 MB 4.5 MB/s eta 0:00:02\n",
            "     -------------------- ------------------- 6.5/12.9 MB 4.5 MB/s eta 0:00:02\n",
            "     -------------------- ------------------- 6.6/12.9 MB 4.3 MB/s eta 0:00:02\n",
            "     --------------------- ------------------ 7.0/12.9 MB 4.5 MB/s eta 0:00:02\n",
            "     ---------------------- ----------------- 7.3/12.9 MB 4.5 MB/s eta 0:00:02\n",
            "     ----------------------- ---------------- 7.5/12.9 MB 4.6 MB/s eta 0:00:02\n",
            "     ------------------------ --------------- 7.8/12.9 MB 4.6 MB/s eta 0:00:02\n",
            "     ------------------------ --------------- 7.9/12.9 MB 4.5 MB/s eta 0:00:02\n",
            "     ------------------------- -------------- 8.2/12.9 MB 4.6 MB/s eta 0:00:02\n",
            "     -------------------------- ------------- 8.5/12.9 MB 4.6 MB/s eta 0:00:01\n",
            "     --------------------------- ------------ 8.8/12.9 MB 4.6 MB/s eta 0:00:01\n",
            "     --------------------------- ------------ 9.0/12.9 MB 4.6 MB/s eta 0:00:01\n",
            "     ---------------------------- ----------- 9.3/12.9 MB 4.7 MB/s eta 0:00:01\n",
            "     ----------------------------- ---------- 9.6/12.9 MB 4.7 MB/s eta 0:00:01\n",
            "     ------------------------------ --------- 9.8/12.9 MB 4.7 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 10.1/12.9 MB 4.7 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 10.2/12.9 MB 4.7 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 10.5/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 10.7/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 11.0/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 11.3/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 11.5/12.9 MB 5.1 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 11.6/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 11.9/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 12.0/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 12.2/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 12.5/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.6/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.8/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 12.9/12.9 MB 4.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from es-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (69.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\agasc\\appdata\\roaming\\python\\python312\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\agasc\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "Collecting ca-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ca_core_news_sm-3.7.0/ca_core_news_sm-3.7.0-py3-none-any.whl (19.6 MB)\n",
            "     ---------------------------------------- 0.0/19.6 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/19.6 MB ? eta -:--:--\n",
            "     --------------------------------------- 0.0/19.6 MB 262.6 kB/s eta 0:01:15\n",
            "     --------------------------------------- 0.1/19.6 MB 751.6 kB/s eta 0:00:26\n",
            "      --------------------------------------- 0.3/19.6 MB 1.4 MB/s eta 0:00:14\n",
            "     - -------------------------------------- 0.5/19.6 MB 2.3 MB/s eta 0:00:09\n",
            "     - -------------------------------------- 0.6/19.6 MB 2.4 MB/s eta 0:00:08\n",
            "     - -------------------------------------- 0.8/19.6 MB 2.8 MB/s eta 0:00:07\n",
            "     -- ------------------------------------- 1.0/19.6 MB 2.9 MB/s eta 0:00:07\n",
            "     -- ------------------------------------- 1.2/19.6 MB 3.2 MB/s eta 0:00:06\n",
            "     -- ------------------------------------- 1.4/19.6 MB 3.1 MB/s eta 0:00:06\n",
            "     --- ------------------------------------ 1.6/19.6 MB 3.2 MB/s eta 0:00:06\n",
            "     --- ------------------------------------ 1.8/19.6 MB 3.4 MB/s eta 0:00:06\n",
            "     --- ------------------------------------ 2.0/19.6 MB 3.4 MB/s eta 0:00:06\n",
            "     ---- ----------------------------------- 2.2/19.6 MB 3.4 MB/s eta 0:00:06\n",
            "     ---- ----------------------------------- 2.3/19.6 MB 3.5 MB/s eta 0:00:05\n",
            "     ----- ---------------------------------- 2.5/19.6 MB 3.5 MB/s eta 0:00:05\n",
            "     ----- ---------------------------------- 2.7/19.6 MB 3.5 MB/s eta 0:00:05\n",
            "     ----- ---------------------------------- 2.9/19.6 MB 3.5 MB/s eta 0:00:05\n",
            "     ------ --------------------------------- 3.0/19.6 MB 3.5 MB/s eta 0:00:05\n",
            "     ------ --------------------------------- 3.2/19.6 MB 3.6 MB/s eta 0:00:05\n",
            "     ------ --------------------------------- 3.3/19.6 MB 3.5 MB/s eta 0:00:05\n",
            "     ------- -------------------------------- 3.5/19.6 MB 3.4 MB/s eta 0:00:05\n",
            "     ------- -------------------------------- 3.6/19.6 MB 3.3 MB/s eta 0:00:05\n",
            "     ------- -------------------------------- 3.6/19.6 MB 3.3 MB/s eta 0:00:05\n",
            "     ------- -------------------------------- 3.7/19.6 MB 3.2 MB/s eta 0:00:06\n",
            "     ------- -------------------------------- 3.8/19.6 MB 3.2 MB/s eta 0:00:05\n",
            "     -------- ------------------------------- 3.9/19.6 MB 3.1 MB/s eta 0:00:05\n",
            "     -------- ------------------------------- 4.1/19.6 MB 3.1 MB/s eta 0:00:05\n",
            "     -------- ------------------------------- 4.2/19.6 MB 3.1 MB/s eta 0:00:05\n",
            "     -------- ------------------------------- 4.3/19.6 MB 3.1 MB/s eta 0:00:05\n",
            "     --------- ------------------------------ 4.5/19.6 MB 3.1 MB/s eta 0:00:05\n",
            "     --------- ------------------------------ 4.5/19.6 MB 3.0 MB/s eta 0:00:05\n",
            "     --------- ------------------------------ 4.7/19.6 MB 3.0 MB/s eta 0:00:05\n",
            "     --------- ------------------------------ 4.8/19.6 MB 3.0 MB/s eta 0:00:05\n",
            "     ---------- ----------------------------- 4.9/19.6 MB 3.1 MB/s eta 0:00:05\n",
            "     ---------- ----------------------------- 5.0/19.6 MB 3.0 MB/s eta 0:00:05\n",
            "     ---------- ----------------------------- 5.2/19.6 MB 3.0 MB/s eta 0:00:05\n",
            "     ---------- ----------------------------- 5.3/19.6 MB 3.0 MB/s eta 0:00:05\n",
            "     ----------- ---------------------------- 5.4/19.6 MB 3.0 MB/s eta 0:00:05\n",
            "     ----------- ---------------------------- 5.5/19.6 MB 3.0 MB/s eta 0:00:05\n",
            "     ----------- ---------------------------- 5.6/19.6 MB 3.0 MB/s eta 0:00:05\n",
            "     ----------- ---------------------------- 5.8/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     ------------ --------------------------- 5.9/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     ------------ --------------------------- 6.1/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     ------------ --------------------------- 6.2/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     ------------ --------------------------- 6.3/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 6.4/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 6.5/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 6.7/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 6.8/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 7.0/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 7.1/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 7.2/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     --------------- ------------------------ 7.4/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     --------------- ------------------------ 7.5/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     --------------- ------------------------ 7.6/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     --------------- ------------------------ 7.7/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     ---------------- ----------------------- 7.9/19.6 MB 2.9 MB/s eta 0:00:05\n",
            "     ---------------- ----------------------- 8.1/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     ---------------- ----------------------- 8.2/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 8.4/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 8.5/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 8.7/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 8.8/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 9.0/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 9.0/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 9.2/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     ------------------- -------------------- 9.3/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     ------------------- -------------------- 9.5/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     ------------------- -------------------- 9.6/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     -------------------- ------------------- 9.8/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     -------------------- ------------------- 10.0/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     -------------------- ------------------- 10.1/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     -------------------- ------------------- 10.2/19.6 MB 2.9 MB/s eta 0:00:04\n",
            "     --------------------- ------------------ 10.4/19.6 MB 3.0 MB/s eta 0:00:04\n",
            "     --------------------- ------------------ 10.6/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     --------------------- ------------------ 10.7/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     ---------------------- ----------------- 10.8/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     ---------------------- ----------------- 11.0/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     ---------------------- ----------------- 11.2/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 11.3/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 11.5/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 11.6/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     ------------------------ --------------- 11.9/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     ------------------------ --------------- 12.1/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     ------------------------ --------------- 12.2/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     ------------------------- -------------- 12.3/19.6 MB 2.9 MB/s eta 0:00:03\n",
            "     ------------------------- -------------- 12.6/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     -------------------------- ------------- 12.7/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     -------------------------- ------------- 12.9/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     -------------------------- ------------- 13.1/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     --------------------------- ------------ 13.2/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     --------------------------- ------------ 13.4/19.6 MB 3.0 MB/s eta 0:00:03\n",
            "     --------------------------- ------------ 13.6/19.6 MB 3.0 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 13.8/19.6 MB 3.0 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 14.0/19.6 MB 3.1 MB/s eta 0:00:02\n",
            "     ----------------------------- ---------- 14.2/19.6 MB 3.1 MB/s eta 0:00:02\n",
            "     ----------------------------- ---------- 14.4/19.6 MB 3.2 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 14.7/19.6 MB 3.2 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 14.9/19.6 MB 3.2 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 15.0/19.6 MB 3.2 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 15.2/19.6 MB 3.3 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 15.4/19.6 MB 3.3 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 15.6/19.6 MB 3.4 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 15.8/19.6 MB 3.4 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 16.0/19.6 MB 3.4 MB/s eta 0:00:02\n",
            "     --------------------------------- ------ 16.3/19.6 MB 3.5 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 16.5/19.6 MB 3.6 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 16.7/19.6 MB 3.6 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 16.8/19.6 MB 3.6 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 16.9/19.6 MB 3.6 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 16.9/19.6 MB 3.6 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 17.1/19.6 MB 3.6 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 17.1/19.6 MB 3.5 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 17.3/19.6 MB 3.5 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 17.3/19.6 MB 3.5 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 17.5/19.6 MB 3.5 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 17.6/19.6 MB 3.5 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 17.8/19.6 MB 3.5 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 18.0/19.6 MB 3.6 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 18.3/19.6 MB 3.6 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 18.4/19.6 MB 3.6 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 18.6/19.6 MB 3.6 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 18.9/19.6 MB 3.6 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 19.1/19.6 MB 3.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------  19.2/19.6 MB 3.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------  19.3/19.6 MB 3.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------  19.5/19.6 MB 3.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------  19.5/19.6 MB 3.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 19.6/19.6 MB 3.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ca-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (69.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\agasc\\appdata\\roaming\\python\\python312\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\agasc\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (0.4.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\agasc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ca-core-news-sm==3.7.0) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ca_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download es_core_news_sm\n",
        "!python -m spacy download ca_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PzrC9--iv-FW"
      },
      "outputs": [],
      "source": [
        "# 1 Remove pacient information and redacted entries\n",
        "def remove_pacient_info(text):\n",
        "    # Remove lines starting with \"nº historia clinica:\" and ending with \"motiu d'ingres\"\n",
        "    text = re.sub(r'nº historia clinica:.*?motiu d\\'ingres', '', text, flags=re.DOTALL)\n",
        "    # Remove lines starting with \"nhc\" and ending with \"lopd\"\n",
        "    text = re.sub(r'nhc.*?lopd', '', text, flags=re.DOTALL)\n",
        "    # Remove all asterisks '*'\n",
        "    text = text.replace('*', '')\n",
        "    return text\n",
        "\n",
        "\n",
        "# 2 Remove Punctuation (Able to be turned ON/OFF)\n",
        "def remove_punctuation(text):\n",
        "    # Define a translation table to map punctuation to None\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # Remove punctuation using the translation table\n",
        "    text = text.translate(translator)\n",
        "    return text\n",
        "\n",
        "\n",
        "# 3 Spell cheking with language detection (Able to be turned ON/OFF)\n",
        "# Load language models for Spanish and Catalan\n",
        "nlp_es = spacy.load(\"es_core_news_sm\")\n",
        "nlp_ca = spacy.load(\"ca_core_news_sm\")\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    # Detect the language of the text\n",
        "    language = detect(text)\n",
        "\n",
        "    # Tokenize the text using the appropriate language model\n",
        "    if language == 'ca':\n",
        "        doc = nlp_ca(text)\n",
        "    else:\n",
        "        doc = nlp_es(text)\n",
        "\n",
        "    # Lemmatize tokens\n",
        "    lemmatized_tokens = []\n",
        "    for token in doc:\n",
        "        # Check if the token is a punctuation or whitespace\n",
        "        if not token.is_punct and not token.is_space:\n",
        "            # Lemmatize the token\n",
        "            lemmatized_token = token.lemma_ if token.lemma_ != '-PRON-' else token.text\n",
        "            lemmatized_tokens.append(lemmatized_token)\n",
        "        else:\n",
        "            lemmatized_tokens.append(token.text)\n",
        "\n",
        "    # Join the tokens back into text\n",
        "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
        "    return lemmatized_text\n",
        "\n",
        "\n",
        "# 4 Tokenization with coordinates of the original text for (evaluation)\n",
        "def tokenize_with_coordinates(text):\n",
        "    # Tokenize the text while preserving the coordinates\n",
        "    tokens_with_coordinates = []\n",
        "    token_start = 0\n",
        "    for token in re.finditer(r'\\S+', text):\n",
        "        token_text = token.group(0)\n",
        "        token_end = token_start + len(token_text)\n",
        "        tokens_with_coordinates.append((token_text, token_start, token_end))\n",
        "        # Update token start position for the next token\n",
        "        token_start = token_end\n",
        "    return tokens_with_coordinates\n",
        "\n",
        "\n",
        "# Main function to process the text\n",
        "def pre_process_text(text, remove_punctuation_call=True, spell_check_call=True):\n",
        "\n",
        "    # 1 Remove pacient information and redacted entries\n",
        "    preprocessed_text = remove_pacient_info(text)\n",
        "\n",
        "    # 2 Remove punctuation if specified\n",
        "    if remove_punctuation_call:\n",
        "        preprocessed_text = remove_punctuation(preprocessed_text)\n",
        "\n",
        "    # 3 Spell check and lemmatize if specified\n",
        "    if spell_check_call:\n",
        "        preprocessed_text = lemmatize_text(preprocessed_text)\n",
        "\n",
        "    # 4 Tokenize the text with coordinates\n",
        "    tokens_with_coordinates = tokenize_with_coordinates(preprocessed_text)\n",
        "\n",
        "    return tokens_with_coordinates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <span style=\"color:red; font-size:larger;\">**DATA ANNOTATION**</span>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def strip_tokens(tagged_text):\n",
        "    def find_indices(tokens, start_token, end_token, occurrence=1):\n",
        "        start_index = None\n",
        "        end_index = None\n",
        "        end_token_count = 0\n",
        "        for i, (word, _, _) in enumerate(tokens):\n",
        "            if word == start_token and start_index is None:\n",
        "                start_index = i\n",
        "            if word == end_token:\n",
        "                end_token_count += 1\n",
        "                if end_token_count == occurrence:\n",
        "                    end_index = i\n",
        "                    break\n",
        "        return start_index, end_index\n",
        "\n",
        "    # Remove sections from \"nº\" to the second occurrence of \"d'ingres\"\n",
        "    start1, end1 = find_indices(tagged_text, 'nº', \"d'ingres\", occurrence=2)\n",
        "    if end1 is not None:\n",
        "        end1 += 1  # Include the end token\n",
        "\n",
        "    # If the indices are found, remove the section\n",
        "    new_tagged_text = []\n",
        "    if start1 is not None and end1 is not None:\n",
        "        new_tagged_text = tagged_text[:start1] + tagged_text[end1:]\n",
        "    else:\n",
        "        new_tagged_text = tagged_text[:]\n",
        "\n",
        "    # Continuously find and remove all sections from \"nhc\" to \"lopd\"\n",
        "    while True:\n",
        "        start2, end2 = find_indices(new_tagged_text, 'nhc', 'lopd')\n",
        "        if start2 is not None and end2 is not None:\n",
        "            end2 += 1  # Include the end token\n",
        "            new_tagged_text = new_tagged_text[:start2] + new_tagged_text[end2:]\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return new_tagged_text\n",
        "\n",
        "def tag_words_from_json(json_data):\n",
        "    # Initialize lists for all tagged texts and counts\n",
        "    all_tagged_texts = []\n",
        "    all_counts = []\n",
        "\n",
        "    # Iterate through each entry in the JSON data\n",
        "    for entry in json_data:\n",
        "        # Extract text and predictions from JSON entry\n",
        "        text = entry['data']['text']\n",
        "        predictions = entry['predictions'][0]['result']\n",
        "\n",
        "        # Initialize counters\n",
        "        counts = {'NEG': 0, 'NSCO': 0, 'UNC': 0, 'USCO': 0}\n",
        "\n",
        "        # Initialize tokens and their coordinates\n",
        "        tokens = []\n",
        "        start_pos = 0\n",
        "\n",
        "        # Split text into tokens while tracking their start and end positions\n",
        "        for word in text.split():\n",
        "            start = text.find(word, start_pos)\n",
        "            end = start + len(word)\n",
        "            tokens.append((word, start, end))\n",
        "            start_pos = end\n",
        "\n",
        "        # Initialize tags list\n",
        "        tags = ['O'] * len(tokens)\n",
        "\n",
        "        # Tag each word\n",
        "        for pred in predictions:\n",
        "            pred_start = pred['value']['start']\n",
        "            pred_end = pred['value']['end']\n",
        "            label = pred['value']['labels'][0]\n",
        "\n",
        "            if label in counts:\n",
        "                counts[label] += 1\n",
        "                for i, (word, start, end) in enumerate(tokens):\n",
        "                    if start < pred_end and end > pred_start:\n",
        "                        tags[i] = label\n",
        "\n",
        "        # Combine tokens with tags\n",
        "        tagged_text = [(token[0], (token[1], token[2]), tags[i]) for i, token in enumerate(tokens)]\n",
        "\n",
        "        # Strip unwanted tokens\n",
        "        stripped_tagged_text = strip_tokens(tagged_text)\n",
        "\n",
        "        # Append the results to the lists\n",
        "        all_tagged_texts.append(stripped_tagged_text)\n",
        "        all_counts.append(counts)\n",
        "\n",
        "    # Return the list of tagged words and counts for all entries\n",
        "    return all_tagged_texts, all_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of entries in the entry: 254\n",
            "[('paciente', (315, 323), 'O'), ('que', (324, 327), 'O'), ('ingresa', (328, 335), 'O'), ('de', (336, 338), 'O'), ('forma', (339, 344), 'O'), ('programada', (345, 355), 'O'), ('para', (356, 360), 'O'), ('realizacion', (361, 372), 'O'), ('de', (373, 375), 'O'), ('uretrotomia', (376, 387), 'O'), ('interna', (388, 395), 'O'), ('.', (396, 397), 'O'), ('antecedents', (398, 409), 'O'), ('alergia', (410, 417), 'O'), ('a', (418, 419), 'O'), ('penicilina', (420, 430), 'O'), ('y', (431, 432), 'O'), ('cloramfenicol', (433, 446), 'O'), ('.', (447, 448), 'O'), ('no', (449, 451), 'NEG'), ('habitos', (452, 459), 'NSCO'), ('toxicos.', (460, 468), 'NSCO'), ('antecedentes', (469, 481), 'O'), ('medicos:', (482, 490), 'O'), ('bloqueo', (491, 498), 'O'), ('auriculoventricular', (499, 518), 'O'), ('de', (519, 521), 'O'), ('primer', (522, 528), 'O'), ('grado', (529, 534), 'O'), ('hipertension', (535, 547), 'O'), ('arterial.', (548, 557), 'O'), ('diverticulosis', (558, 572), 'O'), ('extensa', (573, 580), 'O'), ('insuficiencia', (581, 594), 'O'), ('renal', (595, 600), 'O'), ('cronica', (601, 608), 'O'), ('colelitiasis', (609, 621), 'O'), ('antecedentes', (622, 634), 'O'), ('quirurgicos:', (635, 647), 'O'), ('exeresis', (648, 656), 'O'), ('de', (657, 659), 'O'), ('lesiones', (660, 668), 'O'), ('cutaneas', (669, 677), 'O'), ('con', (678, 681), 'O'), ('anestesia', (682, 691), 'O'), ('local', (692, 697), 'O'), ('protesis', (698, 706), 'O'), ('total', (707, 712), 'O'), ('de', (713, 715), 'O'), ('cadera', (716, 722), 'O'), ('cordectomia', (723, 734), 'O'), ('herniorrafia', (735, 747), 'O'), ('inguinal', (748, 756), 'O'), ('proces', (757, 763), 'O'), ('actual', (764, 770), 'O'), ('varon', (771, 776), 'O'), ('de', (777, 779), 'O'), ('81a', (780, 783), 'O'), ('que', (784, 787), 'O'), ('a', (788, 789), 'O'), ('raiz', (790, 794), 'O'), ('de', (795, 797), 'O'), ('episodio', (798, 806), 'O'), ('de', (807, 809), 'O'), ('hematuria', (810, 819), 'O'), ('macroscopica', (820, 832), 'O'), ('se', (833, 835), 'O'), ('realiza', (836, 843), 'O'), ('cistoscopia', (844, 855), 'NSCO'), ('que', (856, 859), 'O'), ('es', (860, 862), 'O'), ('negativa', (863, 871), 'NEG'), ('para', (872, 876), 'NSCO'), ('lesiones', (877, 885), 'NSCO'), ('malignas', (886, 894), 'NSCO'), ('pero', (895, 899), 'O'), ('se', (900, 902), 'O'), ('objetiva', (903, 911), 'O'), ('estenosis', (912, 921), 'O'), ('de', (922, 924), 'O'), ('uretra', (925, 931), 'O'), ('.', (932, 933), 'O'), ('se', (934, 936), 'O'), ('intentan', (937, 945), 'O'), ('dilataciones', (946, 958), 'O'), ('progresivas', (959, 970), 'O'), ('en', (971, 973), 'O'), ('el', (974, 976), 'O'), ('gabinete', (977, 985), 'O'), ('de', (986, 988), 'O'), ('urologia', (989, 997), 'O'), ('sin', (998, 1001), 'NEG'), ('exito.', (1002, 1008), 'NSCO'), ('se', (1009, 1011), 'O'), ('solicita', (1012, 1020), 'O'), ('estudio', (1021, 1028), 'O'), ('de', (1029, 1031), 'O'), ('imagen', (1032, 1038), 'O'), ('que', (1039, 1042), 'O'), ('confirma', (1043, 1051), 'O'), ('la', (1052, 1054), 'O'), ('existencia', (1055, 1065), 'O'), ('de', (1066, 1068), 'O'), ('estenosis', (1069, 1078), 'O'), ('a', (1079, 1080), 'O'), ('nivel', (1081, 1086), 'O'), ('d', (1087, 1088), 'O'), ('uretra', (1089, 1095), 'O'), ('bulbar', (1096, 1102), 'O'), ('por', (1103, 1106), 'O'), ('lo', (1107, 1109), 'O'), ('que', (1110, 1113), 'O'), ('se', (1114, 1116), 'O'), ('indica', (1117, 1123), 'O'), ('uretrtomia', (1124, 1134), 'O'), ('interna.', (1135, 1143), 'O'), ('exploracio', (1144, 1154), 'O'), ('complementaria', (1155, 1169), 'O'), ('uretrocistografia', (1170, 1187), 'O'), ('retrograda', (1188, 1198), 'O'), ('+', (1199, 1200), 'O'), ('cums', (1201, 1205), 'O'), ('(11/2017):', (1206, 1216), 'O'), ('la', (1217, 1219), 'O'), ('uretrografia', (1220, 1232), 'O'), ('retrograda', (1233, 1243), 'O'), ('muestra', (1244, 1251), 'O'), ('una', (1252, 1255), 'O'), ('uretra', (1256, 1262), 'O'), ('anterior', (1263, 1271), 'O'), ('con', (1272, 1275), 'O'), ('dos', (1276, 1279), 'O'), ('estenosis', (1280, 1289), 'O'), ('focales', (1290, 1297), 'O'), ('a', (1298, 1299), 'O'), ('nivel', (1300, 1305), 'O'), ('de', (1306, 1308), 'O'), ('uretra', (1309, 1315), 'O'), ('peneana', (1316, 1323), 'O'), ('y', (1324, 1325), 'O'), ('bulbar,', (1326, 1333), 'O'), ('aunque', (1334, 1340), 'O'), ('se', (1341, 1343), 'O'), ('observa', (1344, 1351), 'O'), ('paso', (1352, 1356), 'O'), ('de', (1357, 1359), 'O'), ('contraste', (1360, 1369), 'O'), ('retrogrado', (1370, 1380), 'O'), ('a', (1381, 1382), 'O'), ('vejiga.', (1383, 1390), 'O'), ('vejiga', (1391, 1397), 'O'), ('de', (1398, 1400), 'O'), ('correcta', (1401, 1409), 'O'), ('capacidad', (1410, 1419), 'O'), ('(250', (1420, 1424), 'O'), ('cc', (1425, 1427), 'O'), ('de', (1428, 1430), 'O'), ('contraste),', (1431, 1442), 'O'), ('de', (1443, 1445), 'O'), ('paredes', (1446, 1453), 'O'), ('trabeculadas', (1454, 1466), 'O'), ('y', (1467, 1468), 'O'), ('con', (1469, 1472), 'O'), ('diverticulos,', (1473, 1486), 'O'), ('el', (1487, 1489), 'O'), ('mayor', (1490, 1495), 'O'), ('de', (1496, 1498), 'O'), ('ellos', (1499, 1504), 'O'), ('en', (1505, 1507), 'O'), ('cara', (1508, 1512), 'O'), ('posterolateral', (1513, 1527), 'O'), ('izquierda,', (1528, 1538), 'O'), ('sin', (1539, 1542), 'NEG'), ('observarse', (1543, 1553), 'NSCO'), ('defectos', (1554, 1562), 'NSCO'), ('de', (1563, 1565), 'NSCO'), ('replecion.', (1566, 1576), 'NSCO'), ('la', (1577, 1579), 'O'), ('uretrografia', (1580, 1592), 'O'), ('miccional', (1593, 1602), 'O'), ('muestra', (1603, 1610), 'O'), ('una', (1611, 1614), 'O'), ('uretra', (1615, 1621), 'O'), ('prostatica', (1622, 1632), 'O'), ('dilatada,', (1633, 1642), 'O'), ('sin', (1643, 1646), 'UNC'), ('claras', (1647, 1653), 'UNC'), ('estenosis', (1654, 1663), 'USCO'), ('focales', (1664, 1671), 'USCO'), ('confirmandose', (1672, 1685), 'USCO'), ('la', (1686, 1688), 'USCO'), ('existencia', (1689, 1699), 'USCO'), ('de', (1700, 1702), 'USCO'), ('las', (1703, 1706), 'USCO'), ('dos', (1707, 1710), 'USCO'), ('estenosis', (1711, 1720), 'USCO'), ('de', (1721, 1723), 'USCO'), ('uretra', (1724, 1730), 'USCO'), ('anterior', (1731, 1739), 'USCO'), ('descritas', (1740, 1749), 'USCO'), ('previamente.', (1750, 1762), 'USCO'), ('moderado', (1763, 1771), 'O'), ('residuo', (1772, 1779), 'O'), ('postmiccional', (1780, 1793), 'O'), ('en', (1794, 1796), 'O'), ('vejiga', (1797, 1803), 'O'), ('asi', (1804, 1807), 'O'), ('como', (1808, 1812), 'O'), ('en', (1813, 1815), 'O'), ('el', (1816, 1818), 'O'), ('interior', (1819, 1827), 'O'), ('del', (1828, 1831), 'O'), ('diverticulo', (1832, 1843), 'O'), ('posterolateral', (1844, 1858), 'O'), ('izquierdo', (1859, 1868), 'O'), ('descrito.', (1869, 1878), 'O'), ('uretroscopia', (1879, 1891), 'O'), ('(10/2017)', (1892, 1901), 'O'), ('falsa', (1902, 1907), 'UNC'), ('via', (1908, 1911), 'USCO'), ('a', (1912, 1913), 'USCO'), ('nivel', (1914, 1919), 'USCO'), ('de', (1920, 1922), 'USCO'), ('uretra', (1923, 1929), 'USCO'), ('peneana,', (1930, 1938), 'USCO'), ('siguiendo', (1939, 1948), 'O'), ('la', (1949, 1951), 'O'), ('uretra', (1952, 1958), 'O'), ('se', (1959, 1961), 'O'), ('detecta', (1962, 1969), 'O'), ('gran', (1970, 1974), 'O'), ('estenosis', (1975, 1984), 'O'), ('que', (1985, 1988), 'O'), ('no', (1989, 1991), 'NEG'), ('permite', (1992, 1999), 'NSCO'), ('el', (2000, 2002), 'NSCO'), ('paso', (2003, 2007), 'NSCO'), ('de', (2008, 2010), 'NSCO'), ('una', (2011, 2014), 'NSCO'), ('guia.', (2015, 2020), 'NSCO'), ('evolucio', (2066, 2074), 'O'), ('clinica', (2075, 2082), 'O'), ('el', (2083, 2085), 'O'), ('24', (2086, 2088), 'O'), ('de', (2089, 2091), 'O'), ('julio', (2092, 2097), 'O'), ('de', (2098, 2100), 'O'), ('2018', (2101, 2105), 'O'), ('con', (2106, 2109), 'O'), ('el', (2110, 2112), 'O'), ('consentimiento', (2113, 2127), 'O'), ('informado', (2128, 2137), 'O'), ('del', (2138, 2141), 'O'), ('paciente', (2142, 2150), 'O'), ('y', (2151, 2152), 'O'), ('sin', (2153, 2156), 'NEG'), ('contraindicacion', (2157, 2173), 'NSCO'), ('preoperatoria', (2174, 2187), 'NSCO'), ('se', (2188, 2190), 'O'), ('realiza', (2191, 2198), 'O'), ('uretrotomia', (2199, 2210), 'O'), ('interna', (2211, 2218), 'O'), ('sin', (2219, 2222), 'NEG'), ('incidencias.', (2223, 2235), 'NSCO'), ('tras', (2236, 2240), 'O'), ('el', (2241, 2243), 'O'), ('procedimiento', (2244, 2257), 'O'), ('el', (2258, 2260), 'O'), ('paciente', (2261, 2269), 'O'), ('es', (2270, 2272), 'O'), ('trasladado', (2273, 2283), 'O'), ('a', (2284, 2285), 'O'), ('la', (2286, 2288), 'O'), ('planta', (2289, 2295), 'O'), ('de', (2296, 2298), 'O'), ('hospitalizacion', (2299, 2314), 'O'), ('siendo', (2315, 2321), 'O'), ('portador', (2322, 2330), 'O'), ('de', (2331, 2333), 'O'), ('lavado', (2334, 2340), 'O'), ('vesical', (2341, 2348), 'O'), ('continuo.', (2349, 2358), 'O'), ('posteriormente', (2359, 2373), 'O'), ('se', (2374, 2376), 'O'), ('mantiene', (2377, 2385), 'O'), ('en', (2386, 2388), 'O'), ('buen', (2389, 2393), 'O'), ('estado', (2394, 2400), 'O'), ('general,', (2401, 2409), 'O'), ('afebril,', (2410, 2418), 'NEG'), ('hemodinamicamente', (2419, 2436), 'O'), ('estable', (2437, 2444), 'O'), ('y', (2445, 2446), 'O'), ('con', (2447, 2450), 'O'), ('buen', (2451, 2455), 'O'), ('control', (2456, 2463), 'O'), ('del', (2464, 2467), 'O'), ('dolor.', (2468, 2474), 'O'), ('aclarado', (2475, 2483), 'O'), ('progresivo', (2484, 2494), 'O'), ('de', (2495, 2497), 'O'), ('la', (2498, 2500), 'O'), ('orina', (2501, 2506), 'O'), ('con', (2507, 2510), 'O'), ('los', (2511, 2514), 'O'), ('lavados', (2515, 2522), 'O'), ('vesicales', (2523, 2532), 'O'), ('continuos,', (2533, 2543), 'O'), ('que', (2544, 2547), 'O'), ('permiten', (2548, 2556), 'O'), ('su', (2557, 2559), 'O'), ('retirada,', (2560, 2569), 'O'), ('conserva', (2570, 2578), 'O'), ('correcta', (2579, 2587), 'O'), ('diuresis.', (2588, 2597), 'O'), ('tolerancia', (2598, 2608), 'O'), ('correcta', (2609, 2617), 'O'), ('a', (2618, 2619), 'O'), ('dieta', (2620, 2625), 'O'), ('oral.', (2626, 2631), 'O'), ('dada', (2632, 2636), 'O'), ('la', (2637, 2639), 'O'), ('buena', (2640, 2645), 'O'), ('evolucion', (2646, 2655), 'O'), ('se', (2656, 2658), 'O'), ('decide', (2659, 2665), 'O'), ('alta', (2666, 2670), 'O'), ('domiciliaria', (2671, 2683), 'O'), ('siendo', (2684, 2690), 'O'), ('portador', (2691, 2699), 'O'), ('de', (2700, 2702), 'O'), ('sonda', (2703, 2708), 'O'), ('vesical.', (2709, 2717), 'O'), ('orientacio', (2718, 2728), 'O'), ('diagnostica', (2729, 2740), 'O'), ('n40.0', (2741, 2746), 'O'), ('hiperplasia', (2747, 2758), 'O'), ('prostatica', (2759, 2769), 'O'), ('benigna', (2770, 2777), 'O'), ('sense', (2778, 2783), 'O'), ('simptomes', (2784, 2793), 'O'), ('en', (2794, 2796), 'O'), ('les', (2797, 2800), 'O'), ('vies', (2801, 2805), 'O'), ('urinaries', (2806, 2815), 'O'), ('inferiors', (2816, 2825), 'O'), ('procediments', (2826, 2838), 'O'), ('04.81', (2839, 2844), 'O'), ('injeccio', (2845, 2853), 'O'), ('en', (2854, 2856), 'O'), ('el', (2857, 2859), 'O'), ('nervi', (2860, 2865), 'O'), ('periferic', (2866, 2875), 'O'), (\"d'anestesic\", (2876, 2887), 'O'), ('per', (2888, 2891), 'O'), ('a', (2892, 2893), 'O'), ('analgesia', (2894, 2903), 'O'), ('58.0', (2904, 2908), 'O'), ('uretrotomia.', (2909, 2921), 'O'), ('excisio', (2922, 2929), 'O'), ('de', (2930, 2932), 'O'), ('septe', (2933, 2938), 'O'), ('uretral,', (2939, 2947), 'O'), ('uretrostomia', (2948, 2960), 'O'), ('perineal,', (2961, 2970), 'O'), ('extraccio', (2971, 2980), 'O'), ('de', (2981, 2983), 'O'), ('calcul', (2984, 2990), 'O'), ('uretral', (2991, 2998), 'O'), ('per', (2999, 3002), 'O'), ('incisio', (3003, 3010), 'O'), ('sonda', (3011, 3016), 'O'), ('vesical', (3017, 3024), 'O'), ('profilaxis', (3025, 3035), 'O'), ('antibiotica,', (3036, 3048), 'O'), ('antilucerosa', (3049, 3061), 'O'), ('y', (3062, 3063), 'O'), ('antitrombotica', (3064, 3078), 'O'), ('tractament', (3079, 3089), 'O'), ('i', (3090, 3091), 'O'), ('recomanacions', (3092, 3105), 'O'), ('a', (3106, 3107), 'O'), (\"l'alta\", (3108, 3114), 'O'), ('-abundante', (3115, 3125), 'O'), ('ingesta', (3126, 3133), 'O'), ('de', (3134, 3136), 'O'), ('liquidos', (3137, 3145), 'O'), ('entorno', (3146, 3153), 'O'), ('a', (3154, 3155), 'O'), ('dos', (3156, 3159), 'O'), ('litros', (3160, 3166), 'O'), ('y', (3167, 3168), 'O'), ('medio', (3169, 3174), 'O'), ('de', (3175, 3177), 'O'), ('agua', (3178, 3182), 'O'), ('al', (3183, 3185), 'O'), ('dia.', (3186, 3190), 'O'), ('-puede', (3191, 3197), 'O'), ('orinar', (3198, 3204), 'O'), ('con', (3205, 3208), 'O'), ('restos', (3209, 3215), 'O'), ('de', (3216, 3218), 'O'), ('sangre', (3219, 3225), 'O'), ('durante', (3226, 3233), 'O'), ('las', (3234, 3237), 'O'), ('proximas', (3238, 3246), 'O'), ('semanas.', (3247, 3255), 'O'), ('-es', (3256, 3259), 'O'), ('normal', (3260, 3266), 'O'), ('que', (3267, 3270), 'O'), ('sienta', (3271, 3277), 'O'), ('escozor', (3278, 3285), 'O'), ('al', (3286, 3288), 'O'), ('orinar', (3289, 3295), 'O'), ('y', (3296, 3297), 'O'), ('que', (3298, 3301), 'O'), ('tenga', (3302, 3307), 'O'), ('algun', (3308, 3313), 'O'), ('escape', (3314, 3320), 'O'), ('de', (3321, 3323), 'O'), ('orina', (3324, 3329), 'O'), ('y', (3330, 3331), 'O'), ('urgencia', (3332, 3340), 'O'), ('miccional', (3341, 3350), 'O'), ('al', (3351, 3353), 'O'), ('retirar', (3354, 3361), 'O'), ('la', (3362, 3364), 'O'), ('sonda', (3365, 3370), 'O'), ('vesical.', (3371, 3379), 'O'), ('mantener', (3380, 3388), 'O'), ('sonda', (3389, 3394), 'O'), ('vesical', (3395, 3402), 'O'), ('durante', (3403, 3410), 'O'), ('14', (3411, 3413), 'O'), ('dias', (3414, 3418), 'O'), ('(dos', (3419, 3423), 'O'), ('semanas).', (3424, 3433), 'O'), ('ciprofloxacino', (3434, 3448), 'O'), ('500mg', (3449, 3454), 'O'), ('cada', (3455, 3459), 'O'), ('12h', (3460, 3463), 'O'), ('durante', (3464, 3471), 'O'), ('dos', (3472, 3475), 'O'), ('semanas.', (3476, 3484), 'O'), ('-paracetamol', (3485, 3497), 'O'), ('1', (3498, 3499), 'O'), ('g', (3500, 3501), 'O'), ('cada', (3502, 3506), 'O'), ('8', (3507, 3508), 'O'), ('horas', (3509, 3514), 'O'), ('si', (3515, 3517), 'O'), ('molestias.', (3518, 3528), 'O'), ('-si', (3529, 3532), 'O'), ('fiebre', (3533, 3539), 'O'), ('mayor', (3540, 3545), 'O'), ('de', (3546, 3548), 'O'), ('38ºc,', (3549, 3554), 'O'), ('empeoramiento', (3555, 3568), 'O'), ('claro', (3569, 3574), 'O'), ('del', (3575, 3578), 'O'), ('estado', (3579, 3585), 'O'), ('general', (3586, 3593), 'O'), ('o', (3594, 3595), 'O'), ('imposibilidad', (3596, 3609), 'O'), ('miccional', (3610, 3619), 'O'), ('por', (3620, 3623), 'O'), ('obstruccion', (3624, 3635), 'O'), ('de', (3636, 3638), 'O'), ('sonda', (3639, 3644), 'O'), ('vesical', (3645, 3652), 'O'), ('o', (3653, 3654), 'O'), ('despues', (3655, 3662), 'O'), ('de', (3663, 3665), 'O'), ('su', (3666, 3668), 'O'), ('retirada,', (3669, 3678), 'O'), ('consultar', (3679, 3688), 'O'), ('con', (3689, 3692), 'O'), ('el', (3693, 3695), 'O'), ('servicio', (3696, 3704), 'O'), ('de', (3705, 3707), 'O'), ('urgencias.', (3708, 3718), 'O'), ('-control', (3719, 3727), 'O'), ('en', (3728, 3730), 'O'), ('consultas', (3731, 3740), 'O'), ('externas', (3741, 3749), 'O'), ('de', (3750, 3752), 'O'), ('urologia', (3753, 3761), 'O'), ('segun', (3762, 3767), 'O'), ('cita', (3768, 3772), 'O'), ('en', (3773, 3775), 'O'), ('hoja', (3776, 3780), 'O'), ('adjunta.', (3781, 3789), 'O'), ('destinacio', (3790, 3800), 'O'), ('a', (3801, 3802), 'O'), (\"l'alta:\", (3803, 3810), 'O'), ('a', (3811, 3812), 'O'), ('domicili', (3813, 3821), 'O')]\n",
            "[{'NEG': 8, 'NSCO': 8, 'UNC': 2, 'USCO': 2}, {'NEG': 4, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 10, 'NSCO': 8, 'UNC': 0, 'USCO': 0}, {'NEG': 25, 'NSCO': 22, 'UNC': 8, 'USCO': 8}, {'NEG': 6, 'NSCO': 5, 'UNC': 0, 'USCO': 0}, {'NEG': 16, 'NSCO': 17, 'UNC': 2, 'USCO': 2}, {'NEG': 22, 'NSCO': 22, 'UNC': 0, 'USCO': 0}, {'NEG': 12, 'NSCO': 11, 'UNC': 2, 'USCO': 2}, {'NEG': 9, 'NSCO': 8, 'UNC': 1, 'USCO': 1}, {'NEG': 5, 'NSCO': 5, 'UNC': 0, 'USCO': 0}, {'NEG': 35, 'NSCO': 34, 'UNC': 9, 'USCO': 9}, {'NEG': 13, 'NSCO': 15, 'UNC': 1, 'USCO': 1}, {'NEG': 14, 'NSCO': 14, 'UNC': 0, 'USCO': 0}, {'NEG': 6, 'NSCO': 5, 'UNC': 0, 'USCO': 0}, {'NEG': 17, 'NSCO': 17, 'UNC': 9, 'USCO': 9}, {'NEG': 9, 'NSCO': 9, 'UNC': 6, 'USCO': 5}, {'NEG': 22, 'NSCO': 20, 'UNC': 2, 'USCO': 2}, {'NEG': 13, 'NSCO': 12, 'UNC': 2, 'USCO': 3}, {'NEG': 12, 'NSCO': 12, 'UNC': 0, 'USCO': 0}, {'NEG': 14, 'NSCO': 11, 'UNC': 0, 'USCO': 0}, {'NEG': 6, 'NSCO': 6, 'UNC': 1, 'USCO': 1}, {'NEG': 16, 'NSCO': 16, 'UNC': 0, 'USCO': 0}, {'NEG': 19, 'NSCO': 19, 'UNC': 1, 'USCO': 1}, {'NEG': 3, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 18, 'NSCO': 18, 'UNC': 2, 'USCO': 1}, {'NEG': 41, 'NSCO': 38, 'UNC': 7, 'USCO': 7}, {'NEG': 8, 'NSCO': 7, 'UNC': 1, 'USCO': 1}, {'NEG': 52, 'NSCO': 50, 'UNC': 4, 'USCO': 4}, {'NEG': 38, 'NSCO': 38, 'UNC': 7, 'USCO': 6}, {'NEG': 24, 'NSCO': 22, 'UNC': 2, 'USCO': 2}, {'NEG': 7, 'NSCO': 6, 'UNC': 0, 'USCO': 0}, {'NEG': 28, 'NSCO': 27, 'UNC': 2, 'USCO': 2}, {'NEG': 47, 'NSCO': 45, 'UNC': 4, 'USCO': 4}, {'NEG': 10, 'NSCO': 9, 'UNC': 2, 'USCO': 2}, {'NEG': 35, 'NSCO': 32, 'UNC': 4, 'USCO': 4}, {'NEG': 18, 'NSCO': 16, 'UNC': 5, 'USCO': 5}, {'NEG': 16, 'NSCO': 16, 'UNC': 0, 'USCO': 0}, {'NEG': 18, 'NSCO': 16, 'UNC': 4, 'USCO': 4}, {'NEG': 17, 'NSCO': 17, 'UNC': 5, 'USCO': 5}, {'NEG': 36, 'NSCO': 36, 'UNC': 7, 'USCO': 7}, {'NEG': 1, 'NSCO': 1, 'UNC': 0, 'USCO': 0}, {'NEG': 6, 'NSCO': 6, 'UNC': 0, 'USCO': 0}, {'NEG': 3, 'NSCO': 2, 'UNC': 0, 'USCO': 0}, {'NEG': 11, 'NSCO': 10, 'UNC': 3, 'USCO': 3}, {'NEG': 21, 'NSCO': 21, 'UNC': 1, 'USCO': 1}, {'NEG': 2, 'NSCO': 2, 'UNC': 1, 'USCO': 1}, {'NEG': 5, 'NSCO': 5, 'UNC': 0, 'USCO': 0}, {'NEG': 23, 'NSCO': 23, 'UNC': 2, 'USCO': 2}, {'NEG': 7, 'NSCO': 6, 'UNC': 0, 'USCO': 0}, {'NEG': 3, 'NSCO': 2, 'UNC': 0, 'USCO': 0}, {'NEG': 8, 'NSCO': 8, 'UNC': 0, 'USCO': 0}, {'NEG': 11, 'NSCO': 11, 'UNC': 0, 'USCO': 0}, {'NEG': 47, 'NSCO': 46, 'UNC': 2, 'USCO': 2}, {'NEG': 23, 'NSCO': 23, 'UNC': 0, 'USCO': 0}, {'NEG': 8, 'NSCO': 9, 'UNC': 1, 'USCO': 1}, {'NEG': 17, 'NSCO': 16, 'UNC': 1, 'USCO': 1}, {'NEG': 6, 'NSCO': 5, 'UNC': 2, 'USCO': 2}, {'NEG': 12, 'NSCO': 12, 'UNC': 1, 'USCO': 1}, {'NEG': 33, 'NSCO': 30, 'UNC': 1, 'USCO': 1}, {'NEG': 6, 'NSCO': 6, 'UNC': 1, 'USCO': 1}, {'NEG': 1, 'NSCO': 1, 'UNC': 0, 'USCO': 0}, {'NEG': 6, 'NSCO': 6, 'UNC': 0, 'USCO': 0}, {'NEG': 52, 'NSCO': 49, 'UNC': 5, 'USCO': 5}, {'NEG': 5, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 67, 'NSCO': 59, 'UNC': 8, 'USCO': 8}, {'NEG': 24, 'NSCO': 22, 'UNC': 0, 'USCO': 0}, {'NEG': 26, 'NSCO': 25, 'UNC': 12, 'USCO': 12}, {'NEG': 37, 'NSCO': 37, 'UNC': 12, 'USCO': 12}, {'NEG': 21, 'NSCO': 20, 'UNC': 2, 'USCO': 2}, {'NEG': 8, 'NSCO': 8, 'UNC': 0, 'USCO': 0}, {'NEG': 3, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 13, 'NSCO': 13, 'UNC': 1, 'USCO': 1}, {'NEG': 24, 'NSCO': 23, 'UNC': 3, 'USCO': 3}, {'NEG': 5, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 56, 'NSCO': 53, 'UNC': 3, 'USCO': 3}, {'NEG': 31, 'NSCO': 29, 'UNC': 4, 'USCO': 4}, {'NEG': 16, 'NSCO': 16, 'UNC': 0, 'USCO': 0}, {'NEG': 6, 'NSCO': 5, 'UNC': 0, 'USCO': 0}, {'NEG': 3, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 5, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 21, 'NSCO': 21, 'UNC': 16, 'USCO': 16}, {'NEG': 9, 'NSCO': 8, 'UNC': 0, 'USCO': 0}, {'NEG': 16, 'NSCO': 16, 'UNC': 1, 'USCO': 1}, {'NEG': 87, 'NSCO': 84, 'UNC': 23, 'USCO': 22}, {'NEG': 9, 'NSCO': 9, 'UNC': 1, 'USCO': 1}, {'NEG': 8, 'NSCO': 8, 'UNC': 1, 'USCO': 1}, {'NEG': 20, 'NSCO': 20, 'UNC': 2, 'USCO': 2}, {'NEG': 17, 'NSCO': 16, 'UNC': 0, 'USCO': 0}, {'NEG': 13, 'NSCO': 14, 'UNC': 1, 'USCO': 1}, {'NEG': 40, 'NSCO': 39, 'UNC': 0, 'USCO': 0}, {'NEG': 9, 'NSCO': 9, 'UNC': 1, 'USCO': 1}, {'NEG': 25, 'NSCO': 23, 'UNC': 0, 'USCO': 0}, {'NEG': 11, 'NSCO': 10, 'UNC': 2, 'USCO': 2}, {'NEG': 23, 'NSCO': 23, 'UNC': 0, 'USCO': 0}, {'NEG': 39, 'NSCO': 35, 'UNC': 9, 'USCO': 9}, {'NEG': 31, 'NSCO': 28, 'UNC': 3, 'USCO': 3}, {'NEG': 25, 'NSCO': 24, 'UNC': 5, 'USCO': 4}, {'NEG': 12, 'NSCO': 12, 'UNC': 0, 'USCO': 0}, {'NEG': 4, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 18, 'NSCO': 17, 'UNC': 2, 'USCO': 2}, {'NEG': 12, 'NSCO': 13, 'UNC': 4, 'USCO': 5}, {'NEG': 36, 'NSCO': 34, 'UNC': 1, 'USCO': 1}, {'NEG': 6, 'NSCO': 6, 'UNC': 0, 'USCO': 0}, {'NEG': 23, 'NSCO': 22, 'UNC': 0, 'USCO': 0}, {'NEG': 37, 'NSCO': 36, 'UNC': 0, 'USCO': 0}, {'NEG': 3, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 22, 'NSCO': 21, 'UNC': 0, 'USCO': 0}, {'NEG': 20, 'NSCO': 19, 'UNC': 0, 'USCO': 0}, {'NEG': 5, 'NSCO': 5, 'UNC': 0, 'USCO': 0}, {'NEG': 26, 'NSCO': 25, 'UNC': 7, 'USCO': 7}, {'NEG': 23, 'NSCO': 22, 'UNC': 0, 'USCO': 0}, {'NEG': 14, 'NSCO': 14, 'UNC': 0, 'USCO': 0}, {'NEG': 16, 'NSCO': 15, 'UNC': 0, 'USCO': 0}, {'NEG': 9, 'NSCO': 8, 'UNC': 1, 'USCO': 1}, {'NEG': 58, 'NSCO': 56, 'UNC': 5, 'USCO': 5}, {'NEG': 11, 'NSCO': 10, 'UNC': 6, 'USCO': 5}, {'NEG': 65, 'NSCO': 62, 'UNC': 4, 'USCO': 4}, {'NEG': 18, 'NSCO': 18, 'UNC': 1, 'USCO': 1}, {'NEG': 16, 'NSCO': 15, 'UNC': 0, 'USCO': 0}, {'NEG': 36, 'NSCO': 32, 'UNC': 3, 'USCO': 3}, {'NEG': 5, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 4, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 35, 'NSCO': 36, 'UNC': 1, 'USCO': 1}, {'NEG': 22, 'NSCO': 22, 'UNC': 5, 'USCO': 5}, {'NEG': 23, 'NSCO': 24, 'UNC': 0, 'USCO': 0}, {'NEG': 20, 'NSCO': 18, 'UNC': 1, 'USCO': 1}, {'NEG': 10, 'NSCO': 10, 'UNC': 0, 'USCO': 0}, {'NEG': 25, 'NSCO': 24, 'UNC': 1, 'USCO': 1}, {'NEG': 4, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 21, 'NSCO': 21, 'UNC': 5, 'USCO': 1}, {'NEG': 4, 'NSCO': 3, 'UNC': 3, 'USCO': 3}, {'NEG': 5, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 5, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 3, 'NSCO': 2, 'UNC': 0, 'USCO': 0}, {'NEG': 5, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 19, 'NSCO': 17, 'UNC': 3, 'USCO': 3}, {'NEG': 4, 'NSCO': 4, 'UNC': 3, 'USCO': 3}, {'NEG': 6, 'NSCO': 5, 'UNC': 0, 'USCO': 0}, {'NEG': 18, 'NSCO': 15, 'UNC': 3, 'USCO': 3}, {'NEG': 5, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 8, 'NSCO': 6, 'UNC': 0, 'USCO': 0}, {'NEG': 13, 'NSCO': 13, 'UNC': 0, 'USCO': 0}, {'NEG': 13, 'NSCO': 13, 'UNC': 2, 'USCO': 2}, {'NEG': 11, 'NSCO': 11, 'UNC': 2, 'USCO': 2}, {'NEG': 4, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 22, 'NSCO': 24, 'UNC': 0, 'USCO': 0}, {'NEG': 22, 'NSCO': 22, 'UNC': 1, 'USCO': 1}, {'NEG': 13, 'NSCO': 12, 'UNC': 0, 'USCO': 0}, {'NEG': 5, 'NSCO': 4, 'UNC': 2, 'USCO': 2}, {'NEG': 24, 'NSCO': 24, 'UNC': 1, 'USCO': 1}, {'NEG': 21, 'NSCO': 20, 'UNC': 4, 'USCO': 4}, {'NEG': 16, 'NSCO': 16, 'UNC': 0, 'USCO': 0}, {'NEG': 13, 'NSCO': 14, 'UNC': 1, 'USCO': 1}, {'NEG': 5, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 12, 'NSCO': 12, 'UNC': 1, 'USCO': 1}, {'NEG': 4, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 5, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 8, 'NSCO': 7, 'UNC': 5, 'USCO': 5}, {'NEG': 4, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 21, 'NSCO': 20, 'UNC': 0, 'USCO': 0}, {'NEG': 3, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 14, 'NSCO': 14, 'UNC': 0, 'USCO': 0}, {'NEG': 15, 'NSCO': 13, 'UNC': 1, 'USCO': 1}, {'NEG': 25, 'NSCO': 24, 'UNC': 2, 'USCO': 2}, {'NEG': 17, 'NSCO': 16, 'UNC': 2, 'USCO': 2}, {'NEG': 9, 'NSCO': 9, 'UNC': 0, 'USCO': 0}, {'NEG': 9, 'NSCO': 9, 'UNC': 0, 'USCO': 0}, {'NEG': 8, 'NSCO': 8, 'UNC': 0, 'USCO': 0}, {'NEG': 4, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 8, 'NSCO': 6, 'UNC': 1, 'USCO': 1}, {'NEG': 13, 'NSCO': 13, 'UNC': 0, 'USCO': 0}, {'NEG': 43, 'NSCO': 42, 'UNC': 12, 'USCO': 12}, {'NEG': 9, 'NSCO': 8, 'UNC': 0, 'USCO': 0}, {'NEG': 5, 'NSCO': 5, 'UNC': 1, 'USCO': 0}, {'NEG': 21, 'NSCO': 21, 'UNC': 0, 'USCO': 0}, {'NEG': 30, 'NSCO': 29, 'UNC': 2, 'USCO': 2}, {'NEG': 6, 'NSCO': 5, 'UNC': 3, 'USCO': 3}, {'NEG': 13, 'NSCO': 13, 'UNC': 2, 'USCO': 2}, {'NEG': 19, 'NSCO': 18, 'UNC': 2, 'USCO': 2}, {'NEG': 8, 'NSCO': 8, 'UNC': 1, 'USCO': 1}, {'NEG': 29, 'NSCO': 28, 'UNC': 1, 'USCO': 1}, {'NEG': 14, 'NSCO': 14, 'UNC': 0, 'USCO': 0}, {'NEG': 3, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 32, 'NSCO': 31, 'UNC': 2, 'USCO': 2}, {'NEG': 22, 'NSCO': 20, 'UNC': 2, 'USCO': 2}, {'NEG': 6, 'NSCO': 6, 'UNC': 3, 'USCO': 3}, {'NEG': 4, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 34, 'NSCO': 32, 'UNC': 8, 'USCO': 8}, {'NEG': 10, 'NSCO': 10, 'UNC': 0, 'USCO': 0}, {'NEG': 6, 'NSCO': 5, 'UNC': 0, 'USCO': 0}, {'NEG': 11, 'NSCO': 9, 'UNC': 1, 'USCO': 1}, {'NEG': 19, 'NSCO': 19, 'UNC': 1, 'USCO': 1}, {'NEG': 45, 'NSCO': 45, 'UNC': 1, 'USCO': 1}, {'NEG': 5, 'NSCO': 4, 'UNC': 1, 'USCO': 1}, {'NEG': 20, 'NSCO': 18, 'UNC': 1, 'USCO': 1}, {'NEG': 20, 'NSCO': 20, 'UNC': 3, 'USCO': 3}, {'NEG': 32, 'NSCO': 31, 'UNC': 0, 'USCO': 0}, {'NEG': 21, 'NSCO': 21, 'UNC': 1, 'USCO': 1}, {'NEG': 25, 'NSCO': 22, 'UNC': 1, 'USCO': 1}, {'NEG': 21, 'NSCO': 22, 'UNC': 1, 'USCO': 1}, {'NEG': 20, 'NSCO': 18, 'UNC': 4, 'USCO': 4}, {'NEG': 7, 'NSCO': 6, 'UNC': 0, 'USCO': 0}, {'NEG': 3, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 2, 'NSCO': 2, 'UNC': 0, 'USCO': 0}, {'NEG': 29, 'NSCO': 28, 'UNC': 2, 'USCO': 2}, {'NEG': 5, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 8, 'NSCO': 7, 'UNC': 0, 'USCO': 0}, {'NEG': 24, 'NSCO': 25, 'UNC': 0, 'USCO': 0}, {'NEG': 5, 'NSCO': 4, 'UNC': 1, 'USCO': 1}, {'NEG': 7, 'NSCO': 7, 'UNC': 1, 'USCO': 1}, {'NEG': 18, 'NSCO': 17, 'UNC': 2, 'USCO': 2}, {'NEG': 11, 'NSCO': 10, 'UNC': 0, 'USCO': 0}, {'NEG': 8, 'NSCO': 7, 'UNC': 0, 'USCO': 0}, {'NEG': 35, 'NSCO': 35, 'UNC': 3, 'USCO': 3}, {'NEG': 24, 'NSCO': 21, 'UNC': 2, 'USCO': 2}, {'NEG': 19, 'NSCO': 17, 'UNC': 5, 'USCO': 5}, {'NEG': 35, 'NSCO': 34, 'UNC': 1, 'USCO': 1}, {'NEG': 6, 'NSCO': 5, 'UNC': 0, 'USCO': 0}, {'NEG': 32, 'NSCO': 28, 'UNC': 4, 'USCO': 4}, {'NEG': 41, 'NSCO': 40, 'UNC': 7, 'USCO': 7}, {'NEG': 14, 'NSCO': 14, 'UNC': 2, 'USCO': 2}, {'NEG': 4, 'NSCO': 3, 'UNC': 3, 'USCO': 3}, {'NEG': 4, 'NSCO': 3, 'UNC': 3, 'USCO': 3}, {'NEG': 11, 'NSCO': 10, 'UNC': 1, 'USCO': 1}, {'NEG': 16, 'NSCO': 16, 'UNC': 1, 'USCO': 1}, {'NEG': 20, 'NSCO': 17, 'UNC': 0, 'USCO': 0}, {'NEG': 36, 'NSCO': 35, 'UNC': 8, 'USCO': 9}, {'NEG': 7, 'NSCO': 7, 'UNC': 0, 'USCO': 0}, {'NEG': 13, 'NSCO': 13, 'UNC': 0, 'USCO': 0}, {'NEG': 9, 'NSCO': 8, 'UNC': 2, 'USCO': 3}, {'NEG': 13, 'NSCO': 14, 'UNC': 3, 'USCO': 3}, {'NEG': 3, 'NSCO': 3, 'UNC': 0, 'USCO': 0}, {'NEG': 30, 'NSCO': 29, 'UNC': 0, 'USCO': 0}, {'NEG': 25, 'NSCO': 24, 'UNC': 5, 'USCO': 5}, {'NEG': 20, 'NSCO': 20, 'UNC': 0, 'USCO': 0}, {'NEG': 5, 'NSCO': 4, 'UNC': 0, 'USCO': 0}, {'NEG': 30, 'NSCO': 28, 'UNC': 2, 'USCO': 2}, {'NEG': 13, 'NSCO': 13, 'UNC': 0, 'USCO': 0}, {'NEG': 28, 'NSCO': 26, 'UNC': 7, 'USCO': 7}, {'NEG': 16, 'NSCO': 16, 'UNC': 1, 'USCO': 1}, {'NEG': 3, 'NSCO': 2, 'UNC': 0, 'USCO': 0}, {'NEG': 27, 'NSCO': 26, 'UNC': 6, 'USCO': 6}, {'NEG': 6, 'NSCO': 5, 'UNC': 0, 'USCO': 0}, {'NEG': 5, 'NSCO': 5, 'UNC': 0, 'USCO': 0}, {'NEG': 25, 'NSCO': 23, 'UNC': 4, 'USCO': 4}, {'NEG': 30, 'NSCO': 29, 'UNC': 1, 'USCO': 1}, {'NEG': 25, 'NSCO': 25, 'UNC': 3, 'USCO': 3}, {'NEG': 3, 'NSCO': 2, 'UNC': 0, 'USCO': 0}, {'NEG': 10, 'NSCO': 10, 'UNC': 1, 'USCO': 1}, {'NEG': 12, 'NSCO': 10, 'UNC': 1, 'USCO': 1}, {'NEG': 27, 'NSCO': 26, 'UNC': 1, 'USCO': 1}, {'NEG': 9, 'NSCO': 8, 'UNC': 1, 'USCO': 1}, {'NEG': 19, 'NSCO': 17, 'UNC': 1, 'USCO': 1}, {'NEG': 21, 'NSCO': 20, 'UNC': 2, 'USCO': 2}]\n"
          ]
        }
      ],
      "source": [
        "# Example usage with all entries\n",
        "labels, counts_list = tag_words_from_json(training_data)\n",
        "\n",
        "print(\"Number of entries in the entry:\", len(labels))\n",
        "print(labels[0]) # Print out an example entry\n",
        "print(counts_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNlu5qz0WEjh"
      },
      "source": [
        "## <span style=\"color:red; font-size:larger;\">**FEATURE EXTRACTION FUNCTIONS**</span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <span style=\"color:red; font-size:larger;\">**MODEL**</span>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "import logging\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "# Initialize your SpaCy models here\n",
        "nlp_es = spacy.load(\"es_core_news_sm\")\n",
        "nlp_ca = spacy.load(\"ca_core_news_sm\")\n",
        "\n",
        "# Setting up basic configuration for logging\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "special_words = {\"nada\", \"ni\", \"nunca\", \"ningun\", \"ninguno\", \"ninguna\", \"alguna\", \"apenas\", \"para nada\", \"ni siquiera\"}\n",
        "\n",
        "def word2features(doc, i, sentence_index):\n",
        "    word = doc[i].text\n",
        "    import string  # Ensure string module is imported to use string.punctuation\n",
        "\n",
        "    features = {\n",
        "        'WORD': word,\n",
        "        'POS': doc[i].pos_,\n",
        "        'INIT_CAP': word[0].isupper(),\n",
        "        'ALPHANUM': word.isalnum(),\n",
        "        'HAS_NUM': any(char.isdigit() for char in word),\n",
        "        'HAS_CAP': any(char.isupper() for char in word),\n",
        "        'HAS_DASH': '-' in word,\n",
        "        'HAS_US': '_' in word,\n",
        "        'PUNCTUATION': any(char in string.punctuation for char in word),\n",
        "        'SUF2': word[-2:] if len(word) > 1 else '',\n",
        "        'SUF3': word[-3:] if len(word) > 2 else '',\n",
        "        'SUF4': word[-4:] if len(word) > 3 else '',\n",
        "        'PREF2': word[:2] if len(word) > 1 else '',\n",
        "        'PREF3': word[:3] if len(word) > 2 else '',\n",
        "        'PREF4': word[:4] if len(word) > 3 else '',\n",
        "        'SPECIAL': word in special_words\n",
        "    }\n",
        "\n",
        "    if i > 0:\n",
        "        features.update({\n",
        "            '2GRAMBEFORE': ' '.join([doc[i-1].text, word]),\n",
        "            'BEFOREPOS': doc[i-1].pos_\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Mark beginning of sentence\n",
        "\n",
        "    if i < len(doc) - 1:\n",
        "        features.update({\n",
        "            '2GRAMAFTER': ' '.join([word, doc[i+1].text]),\n",
        "            'AFTERPOS': doc[i+1].pos_\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # Mark end of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "def sent2features(sent, lang='es', sentence_index=0):\n",
        "    nlp = nlp_ca if lang == 'ca' else nlp_es\n",
        "    words = [word[0] for word in sent]  # Extract just the words from the sent\n",
        "    spaces = [True] * (len(words) - 1) + [False]  # Space after each word except the last\n",
        "\n",
        "    # Create a Doc from the words and spaces\n",
        "    doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
        "    \n",
        "    features = []\n",
        "    for i in range(len(doc)):\n",
        "        f = word2features(doc, i, sentence_index)\n",
        "        if f is not None:\n",
        "            features.append(f)\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_data_for_crf(json_data):\n",
        "    tagged_texts, counts = tag_words_from_json(json_data)\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    for idx, text in enumerate(tagged_texts): #iterate over the the texts\n",
        "    \n",
        "        features = sent2features(text, detect_language(text), idx) #sends a text to sent2features\n",
        "        labels = [token[2] for token in text]\n",
        "        all_features.append(features)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    return all_features, all_labels\n",
        "\n",
        "def detect_language(text):\n",
        "    # Implement or use a library function to detect language\n",
        "    return 'es'  # or 'ca' based on your detection logic\n",
        "\n",
        "\n",
        "# Prepare features and labels\n",
        "X_train, y_train = prepare_data_for_crf(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the CRF model\n",
        "crf = CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=20,\n",
        "    all_possible_transitions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <span style=\"color:red; font-size:larger;\">**MODEL EVALUATION**</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9368098195835085\n"
          ]
        }
      ],
      "source": [
        "from itertools import chain\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "try:\n",
        "    crf.fit(X_train, y_train)\n",
        "except AttributeError:\n",
        "    pass\n",
        "predictions = crf.predict(X_train)\n",
        "\n",
        "# Flatten the label sequences\n",
        "y_train_flat = list(chain.from_iterable(y_train))\n",
        "predictions_flat = list(chain.from_iterable(predictions))\n",
        "\n",
        "# Now calculate the accuracy\n",
        "accuracy = accuracy_score(y_train_flat, predictions_flat)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
